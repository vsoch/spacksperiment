{
    "url": "https://api.github.com/repos/spack/spack/issues/1738",
    "repository_url": "https://api.github.com/repos/spack/spack",
    "labels_url": "https://api.github.com/repos/spack/spack/issues/1738/labels{/name}",
    "comments_url": "https://api.github.com/repos/spack/spack/issues/1738/comments",
    "events_url": "https://api.github.com/repos/spack/spack/issues/1738/events",
    "html_url": "https://github.com/spack/spack/issues/1738",
    "id": 175920487,
    "node_id": "MDU6SXNzdWUxNzU5MjA0ODc=",
    "number": 1738,
    "title": "Comments on SC16 Slides",
    "user": {
        "login": "citibeth",
        "id": 1924215,
        "node_id": "MDQ6VXNlcjE5MjQyMTU=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1924215?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/citibeth",
        "html_url": "https://github.com/citibeth",
        "followers_url": "https://api.github.com/users/citibeth/followers",
        "following_url": "https://api.github.com/users/citibeth/following{/other_user}",
        "gists_url": "https://api.github.com/users/citibeth/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/citibeth/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/citibeth/subscriptions",
        "organizations_url": "https://api.github.com/users/citibeth/orgs",
        "repos_url": "https://api.github.com/users/citibeth/repos",
        "events_url": "https://api.github.com/users/citibeth/events{/privacy}",
        "received_events_url": "https://api.github.com/users/citibeth/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [],
    "state": "closed",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2016-09-09T03:38:14Z",
    "updated_at": "2017-01-10T18:55:57Z",
    "closed_at": "2017-01-10T18:55:57Z",
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "@tgamblin @alalazo @hegner  @mplegendre @lee218llnl @becker33 \nHere are my comments on the SC16 slides.\n\n**Presenters & Contributors:**\n    Elizabeth Fischer Columbia/NASA\n\n**Spack has vibrant open source community:**\n   NASA/GISS: packaging ice model code\n   Build environment for climate model\n   [I'm adding a second Spack application here...]\n\n**Why use Spack?**\n   The number one reason is because hand-installing a consistent set of dependencies for interesting software projects nowadays is tedious and nearly impossible.  Spack is about 1000 times easier.\n\n**3 major build systems:**\n\nI wouldn't classify Make really as a build system because it doesn't: (a) provide or require standard targets, (b) provide any way (other than typically editing hand-built makefiles) to find/link to dependencies, (c) know how to build modern Fortran correctly with its mod file, (d) provide any way to change compilers.  It would be more accurate to say that bare make is a dependency management system that can be used as the core of a build system.\n\nIn the old days, we wrote makefiles.  Now we have build systems.  There's a difference.\n\nIt's worth pointing out that editing a makefile (or any file that comes with a distribution) causes problems in the modern era of Git and distributed version control.\n\nI think the space on this slide would be put to better use mentioning Python's setup.py build systems --- which ARE a build system, and for which Spack DOES provide support.\n\n**Autotools:**\n\nI don't think users need to know there are three parts of Autotools, or most of the other details on this slide.  They do need to know:\n    a) Autotools-based projects have a configure stage before the build phase.\n    b) The configure stage allows for flexibility in finding/configuring for dependencies and compilers and variants.\n    c) Must Autotools tarballs come with a machine-generated `configure` script.\n    d) `autoreconf` is usually needed for Autools-based projects downloaded from repositories.\n\n**Extensions and Python Support**\n\nI have mixed feelings about this in the tutorial.  Extensions are not necessary; you can just `module load` all the things you need instead.  Extensions also break the combinatorial aspects of Spack: you cannot activate two versions of `py-numpy` for a single `python`.  I see Extensions as a nice feature, but not a core feature.  And because it breaks Spack, I'm not sure we should be pushing users in that direction.\n\n**Spack handles combinatorial software complexity.**\n\nAs for \"installed packages automatically find dependencies\"... this needs the caveat that it only works for compiled binaries.  Not for Python/R/Lua/etc --- where either you activate packages (which breaks a core Spack model), or you `module load` them all (which is equivalent to setting LD_LIBRARY_PATH, with all its evilness).  In a very pratical sense, RPATH only works for compiled binaries.\n\nNow that I mention it... it would be possible to build RPATH-like functionality into Python packages.  When a `.py` file is installed, a little bit would be added to the beginning of each module file that sets up `sys.path` in an RPATH-like way.  Yes, this is all possible.  If done, it would probably need to go in distutils/setup.\n\n**Use spack spec to see the results of concretization**\n\nI would remove the \"Input Spec\" and \"Normalized\" sections to make the remaining text big enought to read.\n\n**Spack package repositories**\n\nThis is a feature I've never used, and never seen used.  I'm skeptical about its value.\n\nThe alternative is to maintain your own Spack branch in a fork.  This has many advantages over creating a separate Spack repository:\n1. It's easy to set up, easy to administer, easy to download.  Just one git repo to clone, and no configuring after-the-fact to point to your special pacakge repo.\n2. You have better control over upgrades: i.e. you merge the latest Spack dev branch into yours when YOU are ready.  When users download your fork, you know they're getting the same version of Spack that worked for you in the past.  If you're distributing software, that is all that matters: that YOUR software is satisfactorally installed.  There is rarely a need to upgrade spack beyond that.\n   \n   3 .It's easier to submit your custom Spack packages to core Spack; just submit a PR.  Or don't, if you don't want them in core Spack.\n3. You can modify core Spack seamlessly along with the packages.  This has been necessary for me so many times so far.  Hopefully not so much in the future.\n\nFor all these reasons, I would recommend replacing the section on Spack package repositories with one showing people a fork-and-customize procedure whereby they fork Spack and then add the custom packages they need to the fork.  I think it's just a better workflow, and I see very few downsides.\n\nThis slide is also poorly motivated:\n- _Some packages can not be released publicly_.  I like to use the word _project_ to describe the upstream tarball / git repo, and _package_ to describe the Spack package.  I think this item is talking about the project, not package.  Even if the project cannot be released publicly, there is often no harm in releasing the Spack package publicly.  Unless Spack has a policy against accepting non-open-source packages...\n\nIn any case... I still see no advantage of separate Spack repos vs. forking Spack (and possibly keeping the fork private).\n\n**Fetching source code for spack**\n\nI would consider reversing the direction of the arrows, to show tarballs flowing FROM the caches, TO Spack.\n\n**Writing Packages - Versions and URLs**\n\nMention that versions should be listed in reverse order.\n\n**Writing Packages -- Variants and Dependencies**\n\nThis example shows problems in PETSc; probably best to fix them in the code.  It should read:\n   `depends_on('python@2.6:2.8', type='build')`\n\nThat brings up the issue... I think that dependency types are important enough that they SHOULD be included inthe tutorial.  In the PETSc example, a needless Python dependencies can and does create problems --- for example, what if you have a PETSc-based package that builds a Python3 extension?  There's no need for a conflict here, as long as the PETSc package specifies a build dependency (which this is; PETSc uses a Python script to configure, rather than a standard build system).\n\n**Modules**\n\nGreat info on module generation.  This is stuff I was not aware of; either because it was not in the manual, or (quite likely) because I didn't read that part of the manual.\n\n**Join the Spack community**\n\nUnder \"Contributing packages to Spack is simple\"... the first step should be to fork Spack.\n\nAgain... the previous slide on multiple Spack repos should be replaced with instructions on forking Spack; since that process will best result in more Spack contributions.\n",
    "performed_via_github_app": null
}